Reference:
[Chapter 3: High-level Language-Specific Analysis and Transformation](https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/)

# **MLIR Toy Chapter 3**

## **Chapter 3: High-level Language-Specific Analysis and Transformation**

## 1. ODS Framework Concepts

The core concept of the ODS framework is to describe the structure and characteristics of an Operation in an MLIR Dialect through a unified definition specification (.td file). This definition file describes various parts of the Operation, such as:

- **Operation name and documentation**
- **Input (arguments) and output (results) types**
- **Builder methods**
- **Verification logic**

Using these definitions, the TableGen tool (`mlir-tblgen`) can automatically generate corresponding C++ code, including the declaration of the Operation, builder methods, verification functions, and auxiliary classes (e.g., Operand Adaptor). This approach introduces the concept of "single source of truth," significantly reducing the burden of manually writing and maintaining repetitive code while promoting automation in the development process.

---

## 2. Parsing Fields in Operation Definitions

The following example of a simple `TransposeOp` (transpose operation) illustrates the key fields:

```
def TransposeOp : Toy_Op<"transpose"> {
  let summary = "transpose operation";

  let arguments = (ins F64Tensor:$input);
  let results = (outs F64Tensor);

  // Allow building a TransposeOp from the input operand.
  let builders = [
    OpBuilder<"Builder *b, OperationState &state, Value input">
  ];

  // Invoke a static verify method to verify this transpose operation.
  let verifier = [{ return ::verify(*this); }];
}
```

### a. `summary` Field

- **Purpose**: Provides a brief description of the Operation, serving as documentation.
- **Explanation**: In this example, the `summary` field is `"transpose operation"`, indicating that this is a transpose operation.

### b. `arguments` and `results` Fields

- **Purpose**: Define the input parameters and output results of the Operation.
- **Explanation**:
    - The `arguments` field defines the input parameters. Here, `(ins F64Tensor:$input)` specifies an input named `input` of type `F64Tensor`.
    - The `results` field defines the output results. Here, `(outs F64Tensor)` specifies that the operation produces a result of type `F64Tensor`.

### c. `builders` Field

- **Purpose**: Defines methods to build the Operation, which are automatically added to the generated C++ class.
- **Explanation**:
    - The example defines a builder prototype: `OpBuilder<"Builder *b, OperationState &state, Value input">`, which allows users to construct a `TransposeOp` using an input operand. Custom build logic can also be implemented in the Dialect module.

### d. `verifier` Field

- **Purpose**: Custom verification logic that is invoked when the Operation is created or used.
- **Explanation**:
    - The content `[{ return ::verify(*this); }]` indicates that the generated verification function will call `::verify(*this)`, allowing developers to add custom verification steps beyond the automatic checks generated by TableGen.

---

## 3. TableGen-Generated C++ Code and Mapping

After defining the Operation in `Ops.td`, the `mlir-tblgen` tool can generate two types of C++ code:

### a. Operation Declaration Code

The following command generates the declaration code:

```bash
$ bin/mlir-tblgen -gen-op-decls ../mlir/examples/toy/Ch2/include/toy/Ops.td -I ../mlir/include/
```

The generated declaration code includes two main parts:

1. **Operand Adaptor Class (e.g., `TransposeOpOperandAdaptor`)**:
    - **Purpose**: Provides a convenient interface for accessing the Operation's operands.
    - **Content**: Includes constructors, `getODSOperands`, and access methods for defined operands (e.g., `input()`).
2. **Operation Class (e.g., `TransposeOp`)**:
    - **Purpose**: Implements the actual Operation class, inheriting from MLIR's `Op` class and applying relevant traits (e.g., `OpTrait::OneResult` and `OpTrait::OneOperand`).
    - **Content**: Includes static methods like `getOperationName()` (returning the name `"toy.transpose"`), operand and result access methods, various `build` methods, and the `verify` method.

Example:

```cpp
//===----------------------------------------------------------------------===//
// toy::TransposeOp declarations
//===----------------------------------------------------------------------===//

class TransposeOpOperandAdaptor {
public:
  TransposeOpOperandAdaptor(ArrayRef<Value> values);
  ArrayRef<Value> getODSOperands(unsigned index);
  Value  input();

private:
  ArrayRef<Value> tblgen_operands;
};

class TransposeOp : public Op<TransposeOp, OpTrait::OneResult, OpTrait::OneOperand> {
public:
  using Op::Op;
  using OperandAdaptor = TransposeOpOperandAdaptor;
  static StringRef getOperationName();
  Operation::operand_range getODSOperands(unsigned index);
  Value  input();
  Operation::result_range getODSResults(unsigned index);
  static void build(Builder *b, OperationState &state, Value input);
  static void build(Builder *odsBuilder, OperationState &odsState, Type resultType0, Value input);
  static void build(Builder *odsBuilder, OperationState &odsState, ArrayRef<Type> resultTypes, Value input);
  static void build(Builder *, OperationState &odsState, ArrayRef<Type> resultTypes, ValueRange operands, ArrayRef<NamedAttribute> attributes);
  LogicalResult verify();
};
```

### b. Operation Definition Code

The following command generates the implementation code:

```bash
$ bin/mlir-tblgen -gen-op-defs ../mlir/examples/toy/Ch2/include/toy/Ops.td -I ../mlir/include/
```

The generated implementation code includes:

1. **Operand Adaptor Implementation**:
    - **Constructor**: Stores all passed operands.
    - **`getODSOperands` Method**: Returns operands within a specific range based on the index.
    - **`input()` Method**: Returns the first operand, corresponding to `$input` in the definition.

    Example:

    ```cpp
    TransposeOpOperandAdaptor::TransposeOpOperandAdaptor(ArrayRef<Value> values) {
      tblgen_operands = values;
    }
    
    ArrayRef<Value> TransposeOpOperandAdaptor::getODSOperands(unsigned index) {
      return {std::next(tblgen_operands.begin(), index), std::next(tblgen_operands.begin(), index + 1)};
    }
    
    Value TransposeOpOperandAdaptor::input() {
      return *getODSOperands(0).begin();
    }
    ```

2. **Operation Class Implementation**:
    - **`getOperationName()`**: Returns the Operation name `"toy.transpose"`.
    - **Operand and Result Access Methods**: Access operands and results via `getODSOperands` and `getODSResults`.
    - **Multiple `build` Methods**: Provide overloaded versions to support different parameter types for construction.
    - **`verify()` Method**: Performs automatic verification and calls custom verification logic.

    Example:

    ```cpp
    StringRef TransposeOp::getOperationName() {
      return "toy.transpose";
    }
    
    Operation::operand_range TransposeOp::getODSOperands(unsigned index) {
      return {std::next(getOperation()->operand_begin(), index), std::next(getOperation()->operand_begin(), index + 1)};
    }
    
    Value TransposeOp::input() {
      return *getODSOperands(0).begin();
    }
    
    Operation::result_range TransposeOp::getODSResults(unsigned index) {
      return {std::next(getOperation()->result_begin(), index), std::next(getOperation()->result_begin(), index + 1)};
    }
    
    void TransposeOp::build(Builder *odsBuilder, OperationState &odsState, Type resultType0, Value input) {
      odsState.addOperands(input);
      odsState.addTypes(resultType0);
    }
    
    void TransposeOp::build(Builder *odsBuilder, OperationState &odsState, ArrayRef<Type> resultTypes, Value input) {
      odsState.addOperands(input);
      odsState.addTypes(resultTypes);
    }
    
    void TransposeOp::build(Builder *, OperationState &odsState, ArrayRef<Type> resultTypes, ValueRange operands, ArrayRef<NamedAttribute> attributes) {
      assert(operands.size() == 1u && "mismatched number of parameters");
      odsState.addOperands(operands);
      odsState.addAttributes(attributes);
      assert(resultTypes.size() == 1u && "mismatched number of return types");
      odsState.addTypes(resultTypes);
    }
    
    LogicalResult TransposeOp::verify() {
      {
        unsigned index = 0; (void)index;
        for (Value v : getODSOperands(0)) {
          (void)v;
          if (!(((v.getType().isa<TensorType>())) && ((v.getType().cast<ShapedType>().getElementType().isF64())))) {
            return emitOpError("operand #") << index << " must be tensor of 64-bit float values, but got " << v.getType();
          }
          ++index;
        }
      }
      {
        unsigned index = 0; (void)index;
        for (Value v : getODSResults(0)) {
          (void)v;
          if (!(((v.getType().isa<TensorType>())) && ((v.getType().cast<ShapedType>().getElementType().isF64())))) {
            return emitOpError("result #") << index << " must be tensor of 64-bit float values, but got " << v.getType();
          }
          ++index;
        }
      }
      if (this->getOperation()->getNumRegions() != 0) {
        return emitOpError("has incorrect number of regions: expected 0 but found ") << this->getOperation()->getNumRegions();
      }
      return ::verify(*this);
    }
    ```

---

## 4. Summary

The ODS framework allows developers to define Operations in TableGen once, generating corresponding C++ code automatically. This ensures consistency and reduces manual maintenance of repetitive code.

- **`summary` and `description`**: Provide documentation for the Operation.
- **`arguments` and `results`**: Define the Operation's inputs and outputs.
- **`builders`**: Generate multiple overloaded `build` methods for constructing the Operation.
- **`verifier`**: Add custom verification logic to the automatically generated verification function.

Finally, the `mlir-tblgen` tool generates declaration and definition code, mapping TableGen definitions to concrete C++ classes. This enables automatic construction, verification, analysis, and printing of Operations in the Dialect, significantly improving project maintainability and development efficiency.

Below is a detailed explanation of the core concepts in Chapter 3 regarding "High-Level Language-Specific Analysis and Transformation," with examples demonstrating two methods for pattern matching and rewriting (expression transformation) in MLIR:

1. **Using C++ Imperative Style for Pattern Matching and Rewriting**
2. **Using Declarative Rewrite Rules (DRR) for Pattern Matching and Rewriting**

---

## 1. Background and Motivation

In MLIR, after generating intermediate representation (IR), subsequent transformations are necessary for code optimization. These transformations involve two key steps:

- **Pattern Matching**: Identifying redundant or optimizable parts of the IR.
- **Rewriting**: Replacing these parts with more efficient, equivalent IR.

High-level language-specific dialects (e.g., Toy Dialect) enable optimizations that are difficult to achieve at lower levels (e.g., LLVM). MLIR's Generic DAG Rewriter framework supports two approaches for pattern matching and rewriting.

---

## 2. Method 1: Using C++ Imperative Style for Matching and Rewriting

### 2.1 Example: Eliminating Redundant Transpose Operations

Consider a Toy function with two consecutive transpose operations:

```
def transpose_transpose(x) {
  return transpose(transpose(x));
}
```

The corresponding MLIR IR might look like this:

```
toy.func @transpose_transpose(%arg0: tensor<*xf64>) -> tensor<*xf64> {
  %0 = "toy.transpose"(%arg0) : (tensor<*xf64>) -> tensor<*xf64>
  %1 = "toy.transpose"(%0) : (tensor<*xf64>) -> tensor<*xf64>
  toy.return %1 : tensor<*xf64>
}
```

Since two transposes cancel each other out, the optimized IR should directly return `%arg0`.

### 2.2 C++ Implementation of Rewrite Rule

A Rewrite Pattern can be implemented in C++ to match and rewrite `transpose(transpose(x))` to `x`:

```cpp
struct SimplifyRedundantTranspose : public mlir::OpRewritePattern<TransposeOp> {
  SimplifyRedundantTranspose(mlir::MLIRContext *context)
      : OpRewritePattern<TransposeOp>(context, /*benefit=*/1) {}

  llvm::LogicalResult
  matchAndRewrite(TransposeOp op, mlir::PatternRewriter &rewriter) const override {
    mlir::Value transposeInput = op.getOperand();
    TransposeOp transposeInputOp = transposeInput.getDefiningOp<TransposeOp>();

    if (!transposeInputOp)
      return failure();

    rewriter.replaceOp(op, {transposeInputOp.getOperand()});
    return success();
  }
};
```

### 2.3 Integration into Canonicalization Pass

To apply the rewrite rule, register it in the canonicalization framework:

```cpp
void TransposeOp::getCanonicalizationPatterns(RewritePatternSet &results,
                                              MLIRContext *context) {
  results.add<SimplifyRedundantTranspose>(context);
}
```

Add the canonicalizer pass to the PassManager:

```cpp
mlir::PassManager pm(module->getName());
pm.addNestedPass<mlir::toy::FuncOp>(mlir::createCanonicalizerPass());
```

After optimization, the IR becomes:

```
toy.func @transpose_transpose(%arg0: tensor<*xf64>) -> tensor<*xf64> {
  toy.return %arg0 : tensor<*xf64>
}
```

---

## 3. Method 2: Using DRR for Matching and Rewriting

### 3.1 Example: Optimizing Redundant Reshape Operations

Consider a Toy program with redundant reshape operations:

```
def main() {
  var a<2,1> = [1, 2];
  var b<2,1> = a;
  var c<2,1> = b;
  print(c);
}
```

The corresponding MLIR IR might include multiple redundant reshape operations. Using DRR, we can define rewrite rules to eliminate them.

### 3.2 DRR Rewrite Rules

Define rewrite rules in TableGen:

```
def ReshapeReshapeOptPattern : Pat<(ReshapeOp(ReshapeOp $arg)),
                                   (ReshapeOp $arg)>;

def TypesAreIdentical : Constraint<CPred<"$0.getType() == $1.getType()">>;

def RedundantReshapeOptPattern : Pat<
  (ReshapeOp:$res $arg), (replaceWithValue $arg),
  [(TypesAreIdentical $res, $arg)]>;

def ReshapeConstant : NativeCodeCall<"$0.reshape(($1.getType()).cast<ShapedType>())">;

def FoldConstantReshapeOptPattern : Pat<
  (ReshapeOp:$res (ConstantOp $arg)),
  (ConstantOp (ReshapeConstant $arg, $res))>;
```

### 3.3 Verification of DRR Optimization

After optimization, the IR becomes:

```
module {
  func @main() {
    %0 = "toy.constant"() {value = dense<[[1.000000e+00], [2.000000e+00]]> : tensor<2x1xf64>}
                           : () -> tensor<2x1xf64>
    "toy.print"(%0) : (tensor<2x1xf64>) -> ()
    "toy.return"() : () -> ()
  }
}
```

---

## 4. Integration into Compilation Pipeline

The transformation process involves:

1. **IR Generation**: MLIRGen compiles high-level language (e.g., Toy) into initial MLIR.
2. **Pass Creation**: Add a canonicalization pass to the PassManager and register custom rewrite rules.
3. **Running Optimization Pass**: The canonicalization pass applies rewrite rules iteratively.
4. **Generating Optimized IR**: The final IR is optimized and ready for code generation.

---

## 5. Conclusion

- **Using C++ Imperative Style**:
    - Define a structure inheriting from `OpRewritePattern<TransposeOp>` and implement `matchAndRewrite()`.
    - Register the pattern in the canonicalization framework.
- **Using DRR**:
    - Define rewrite rules in TableGen and enable `hasCanonicalizer` and `[NoSideEffect]`.
    - Automatically generate C++ code for the rules.
